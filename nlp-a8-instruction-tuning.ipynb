{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5896b1a6-8ed4-4484-96e5-50d0ac10b73a",
   "metadata": {},
   "source": [
    "# [Supervised Fine-tuning Trainer](https://huggingface.co/docs/trl/sft_trainer)\n",
    "\n",
    "Supervised fine-tuning (or SFT for short) is a crucial step in RLHF. In TRL we provide an easy-to-use API to create your SFT models and train them with few lines of code on your dataset.\n",
    "\n",
    "[Python Script](https://github.com/huggingface/trl/blob/main/examples/scripts/sft.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f636b5-91b3-4a45-a6cf-334425eac4df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft==0.7.1 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (0.7.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from peft==0.7.1) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from peft==0.7.1) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from peft==0.7.1) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from peft==0.7.1) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from peft==0.7.1) (2.3.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from peft==0.7.1) (4.36.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from peft==0.7.1) (4.66.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from peft==0.7.1) (0.25.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from peft==0.7.1) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from peft==0.7.1) (0.22.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (2024.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from torch>=1.13.0->peft==0.7.1) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from torch>=1.13.0->peft==0.7.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from torch>=1.13.0->peft==0.7.1) (3.1.3)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from torch>=1.13.0->peft==0.7.1) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from tqdm->peft==0.7.1) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from transformers->peft==0.7.1) (2024.4.16)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from transformers->peft==0.7.1) (0.15.2)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.13.0->peft==0.7.1) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.13.0->peft==0.7.1) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from jinja2->torch>=1.13.0->peft==0.7.1) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from sympy->torch>=1.13.0->peft==0.7.1) (1.3.0)\n",
      "Requirement already satisfied: trl==0.7.4 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (0.7.4)\n",
      "Requirement already satisfied: torch>=1.4.0 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from trl==0.7.4) (2.3.0)\n",
      "Requirement already satisfied: transformers>=4.18.0 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from trl==0.7.4) (4.36.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from trl==0.7.4) (1.24.3)\n",
      "Requirement already satisfied: accelerate in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from trl==0.7.4) (0.25.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from trl==0.7.4) (2.19.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from trl==0.7.4) (0.8.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from torch>=1.4.0->trl==0.7.4) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from torch>=1.4.0->trl==0.7.4) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from torch>=1.4.0->trl==0.7.4) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from torch>=1.4.0->trl==0.7.4) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from torch>=1.4.0->trl==0.7.4) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from torch>=1.4.0->trl==0.7.4) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from torch>=1.4.0->trl==0.7.4) (2021.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.4) (0.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.4) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.4) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.4) (2024.4.16)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.4) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.4) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.4) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.4) (4.66.2)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from tyro>=0.5.11->trl==0.7.4) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from tyro>=0.5.11->trl==0.7.4) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from tyro>=0.5.11->trl==0.7.4) (1.7.1)\n",
      "Requirement already satisfied: colorama>=0.4.0 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from tyro>=0.5.11->trl==0.7.4) (0.4.6)\n",
      "Requirement already satisfied: eval-type-backport>=0.1.3 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from tyro>=0.5.11->trl==0.7.4) (0.2.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from accelerate->trl==0.7.4) (5.9.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from datasets->trl==0.7.4) (16.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from datasets->trl==0.7.4) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from datasets->trl==0.7.4) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from datasets->trl==0.7.4) (2.0.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from datasets->trl==0.7.4) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from datasets->trl==0.7.4) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from datasets->trl==0.7.4) (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp->datasets->trl==0.7.4) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp->datasets->trl==0.7.4) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp->datasets->trl==0.7.4) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp->datasets->trl==0.7.4) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp->datasets->trl==0.7.4) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from aiohttp->datasets->trl==0.7.4) (4.0.3)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.4.0->trl==0.7.4) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.4.0->trl==0.7.4) (2021.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests->transformers>=4.18.0->trl==0.7.4) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests->transformers>=4.18.0->trl==0.7.4) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests->transformers>=4.18.0->trl==0.7.4) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from requests->transformers>=4.18.0->trl==0.7.4) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.4) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.4) (2.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from jinja2->torch>=1.4.0->trl==0.7.4) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from pandas->datasets->trl==0.7.4) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from pandas->datasets->trl==0.7.4) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from pandas->datasets->trl==0.7.4) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from sympy->torch>=1.4.0->trl==0.7.4) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.4) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\anaconda3\\envs\\langchain_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.7.4) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement transformer (from versions: none)\n",
      "ERROR: No matching distribution found for transformer\n"
     ]
    }
   ],
   "source": [
    " !pip3 install peft==0.7.1\n",
    " !pip3 install trl==0.7.4\n",
    " !pip3 install transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd24274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.36.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7263f867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\trl\\trainer\\ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.7.4'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import trl\n",
    "trl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74ed1948-2b9b-4324-ba26-36b6c95fdbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b16f67f1-c0e4-40e9-b192-4d1a9cfbfb17",
   "metadata": {},
   "source": [
    "## Instruction-Tuning\n",
    "Train on completions only\n",
    "- Use the DataCollatorForCompletionOnlyLM to train your model on the generated prompts only.\n",
    "- Note that this works only in the case when packing=False.\n",
    "- To instantiate that collator for instruction data, pass a response template and the tokenizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad1ea5ec-482c-4520-bd97-3ccc1f2961f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 52002 examples [00:00, 132921.24 examples/s]\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\datasets\\load.py:1486: FutureWarning: The repository for tatsu-lab/alpaca_eval contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tatsu-lab/alpaca_eval\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 100%|██████████| 8.10k/8.10k [00:00<?, ?B/s]\n",
      "Downloading readme: 100%|██████████| 30.0/30.0 [00:00<?, ?B/s]\n",
      "Downloading data: 100%|██████████| 621k/621k [00:01<00:00, 575kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\.cache\\huggingface\\datasets\\downloads\\07bde58ae497102ab81d326d84eafcf6c2c7e8df8cd8b8d0ef64d9eceab41ada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating eval split: 805 examples [00:00, 22644.85 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'output'],\n",
       "    num_rows: 805\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Load the dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "train_set = load_dataset('json', data_files='alpaca_data.json', split='train')\n",
    "eval_set = load_dataset(\"tatsu-lab/alpaca_eval\", split='eval')\n",
    "eval_set = eval_set.remove_columns([\"generator\", \"dataset\"])\n",
    "eval_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69100196-d9d8-4791-9e11-6e93f1bd7550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ASUS\\.cache\\huggingface\\hub\\models--distilgpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Load the model & Tokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name_or_path = \"distilgpt2\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    device_map = 'auto')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Make sure to pass a correct value for max_seq_length as the default value will be set to min(tokenizer.model_max_length, 1024).\n",
    "max_seq_length = min(tokenizer.model_max_length, 1024)\n",
    "max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81d350a2-002b-40e2-8c10-9afea5923cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(examples):\n",
    "\toutput_texts = []\n",
    "\n",
    "\tfor i in range(len(examples['instruction'])):\n",
    "\t\tif 'input' in examples.keys():\n",
    "\t\t\tinput_text = examples[\"input\"][i] \n",
    "\t\telse:\n",
    "\t\t\tinput_text = None\n",
    "\t\n",
    "\t\tif input_text:\n",
    "\t\t\ttext = f\"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{examples[\"instruction\"][i]}\n",
    "\n",
    "### Input:\n",
    "{input_text}\n",
    "\n",
    "### Response:\n",
    "{examples[\"output\"][i]}\n",
    "\"\"\".strip()\n",
    "\t\t\t\n",
    "\t\telse:\n",
    "\t\t\ttext = f\"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{examples[\"instruction\"][i]}\n",
    "\n",
    "### Response:\n",
    "{examples[\"output\"][i]}\n",
    "\"\"\".strip()\n",
    "\n",
    "\t\toutput_texts.append(text)\n",
    "\n",
    "\treturn output_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44cf1dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the DataCollatorForCompletionOnlyLM to train your model on the generated prompts only\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28385087-8eb8-4b83-a7dd-1313bf591b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 805/805 [00:00<00:00, 5094.26 examples/s]\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "                                                  \n",
      " 14%|█▍        | 213/1500 [20:37<30:05,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3564, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "                                                  \n",
      " 14%|█▍        | 213/1500 [32:44<30:05,  1.40s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0647, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "                                                  \n",
      " 14%|█▍        | 213/1500 [44:44<30:05,  1.40s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8213, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      "100%|██████████| 1500/1500 [36:43<00:00,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2203.1508, 'train_samples_per_second': 1.362, 'train_steps_per_second': 0.681, 'train_loss': 2.080772501627604, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1500, training_loss=2.080772501627604, metrics={'train_runtime': 2203.1508, 'train_samples_per_second': 1.362, 'train_steps_per_second': 0.681, 'train_loss': 2.080772501627604, 'epoch': 3.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_template = \"### Response:\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n",
    "collator\n",
    "\n",
    "output_path = './model'\n",
    "model_path = './model/finalmodel'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = output_path, #default = 'tmp_trainer'\n",
    "    save_strategy = 'epoch',\n",
    "    gradient_checkpointing = True,\n",
    "    per_device_train_batch_size = 2,\n",
    "    per_device_eval_batch_size = 2,\n",
    "    num_train_epochs = 3, #default = 3\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    args = training_args,\n",
    "    train_dataset = train_set.select(range(1000)),\n",
    "    eval_dataset = eval_set,\n",
    "    formatting_func = formatting_prompts_func,\n",
    "    data_collator = collator,\n",
    "    max_seq_length = max_seq_length,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8eae0de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "trainer.save_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5da45651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map = 'auto')\n",
    "\n",
    "text_generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    device_map = 'auto',\n",
    "    pad_token_id = tokenizer.eos_token_id,\n",
    "    max_new_tokens = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a0a07a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(sample):\n",
    "\t\n",
    "\tif 'input' in sample.keys():\n",
    "\t\treturn f\"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{sample['instruction']}\n",
    "\n",
    "### Input:\n",
    "{sample['input']}\n",
    "\n",
    "### Response:\n",
    "\"\"\".strip()\n",
    "\t\t\t\n",
    "\telse:\n",
    "\t\treturn f\"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{sample['instruction']}\n",
    "\n",
    "### Response:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "53c7be18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:\n",
      "Hi, my sister and her girlfriends want me to play kickball with them. Can you explain how the game is played, so they don't take advantage of me?\n",
      "\n",
      "Gold Response:\n",
      "Kickball is a game similar to baseball, but with a large rubber ball instead of a bat and a ball. The game is usually played with two teams of six players each. Each team has three bases and a home plate. The players on the kicking team line up at home plate and take turns kicking the ball. The object of the game is to score runs by running around all three bases and back to home plate without being tagged out by the defense. The team with the most runs at the end of the game is the winner.\n",
      "\n",
      "Generated Response:\n",
      "The game is played by a team of five players from around the world. The team consists of five or six members of the team. The team will advance to the final round as a result. When your team reaches the last round, they will\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compare_generated_and_gold(pipeline, sample):\n",
    "    formatted_input = format_input(sample)\n",
    "    output = pipeline(formatted_input)\n",
    "    generated_response = output[0]['generated_text'].split(\"### Response:\\n\")[-1]\n",
    "\n",
    "    print(f\"Instruction:\\n{sample['instruction']}\\n\")\n",
    "    if 'input' in sample:\n",
    "        print(f\"Input:\\n{sample['input']}\\n\")\n",
    "    print(f\"Gold Response:\\n{sample['output']}\\n\")\n",
    "    print(f\"Generated Response:\\n{generated_response}\\n\")\n",
    "\n",
    "# Test the function with an example from the eval_set\n",
    "compare_generated_and_gold(text_generator, eval_set[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444e7916",
   "metadata": {},
   "source": [
    "## Findings\n",
    "The generated responses were not closely aligned with the gold standard, indicating issues with the model's understanding and generating relevant content. The decrease in loss during training shows promise, but it's clear that further improvements are needed.\n",
    "\n",
    "## Recommendations\n",
    "\n",
    "### 1. More Training Data\n",
    "- **Action**: Expand the training dataset with more diverse examples.\n",
    "- **Purpose**: To improve generalization over different types of inputs.\n",
    "\n",
    "### 2. Longer Training Periods\n",
    "- **Action**: Increase the number of training epochs.\n",
    "- **Purpose**: To allow the model to learn more detailed features and relationships.\n",
    "\n",
    "### 3. Fine-Tuning on Specific Tasks\n",
    "- **Action**: Fine-tune the model on tasks similar to the expected deployment scenarios.\n",
    "- **Purpose**: To enhance the model's accuracy on specific tasks like understanding and generating game explanations.\n",
    "\n",
    "### 4. Improved Model Architecture\n",
    "- **Action**: Explore advanced model architectures like Transformer-based models (GPT, BERT).\n",
    "- **Purpose**: To better handle nuances and improve context understanding.\n",
    "\n",
    "### 5. Hyperparameter Optimization\n",
    "- **Action**: Experiment with different hyperparameters.\n",
    "- **Purpose**: To find the optimal configuration that maximizes model performance.\n",
    "\n",
    "### 6. Advanced Evaluation Metrics\n",
    "- **Action**: Implement additional metrics such as BLEU, ROUGE for a detailed performance evaluation.\n",
    "- **Purpose**: To gain deeper insights into the model's output quality beyond just loss.\n",
    "\n",
    "### 7. Human-in-the-Loop\n",
    "- **Action**: Incorporate human feedback during training phases.\n",
    "- **Purpose**: To correct and guide the model's learning process more effectively.\n",
    "\n",
    "### 8. Regular Validation\n",
    "- **Action**: Conduct regular tests with new, unseen data.\n",
    "- **Purpose**: To ensure consistent model performance and adapt training strategies as needed.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
